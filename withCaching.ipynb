{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shengtao Lin, Tianhe Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from tweepy) (1.2.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from tweepy) (1.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/LINHTS/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key and tokens\n",
    "#api key: bUvI6HoYH97pwjTmnMNAPTMTS\n",
    "#api secret key: Hp420vZADZ25NMR0sqEf4eVlYXVtUsyL4AhwgdAxTf2ssbr0in\n",
    "#access token: 1190435999551303680-vK990ORPT4tj7KU1TTkfOtARxNzLfz\n",
    "#Access Token Secret: 6KWkz1UYuCPvvGKk22AvMumRpwlA2kO8DlIVZ5KwpQtTK\n",
    "\n",
    "access_token = \"1190435999551303680-vK990ORPT4tj7KU1TTkfOtARxNzLfz\"\n",
    "access_token_secret = \"6KWkz1UYuCPvvGKk22AvMumRpwlA2kO8DlIVZ5KwpQtTK\"\n",
    "consumer_key = \"bUvI6HoYH97pwjTmnMNAPTMTS\"\n",
    "consumer_secret = \"Hp420vZADZ25NMR0sqEf4eVlYXVtUsyL4AhwgdAxTf2ssbr0in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "default_stdout = sys.stdout\n",
    "sys.stdout = open('AI-out', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "End",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m End\n"
     ]
    }
   ],
   "source": [
    "class StdOutListener(StreamListener):\n",
    "    t_count=0\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        print (data)\n",
    "        self.t_count += 1\n",
    "        \n",
    "        #stop by \n",
    "        if self.t_count >=12000:\n",
    "            sys.exit(\"End\")\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print (status)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    l = StdOutListener()\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    stream = Stream(auth, l)\n",
    "\n",
    "    #This line filter Twitter Streams to capture data by the keywords: 'python', 'javascript', 'ruby'\n",
    "    stream.filter(track=['#ArtificialIntelligence'],languages=[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = default_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "count=0\n",
    "with open(\"AI-out\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        count+=1\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            # if you want to see a specific field, you can print it. \n",
    "            #If your file is big, there may be too many of these printed\n",
    "            #print(data['text']) \n",
    "        except:\n",
    "            continue\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBase create/insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database import\n",
    "import mysql.connector\n",
    "import pymongo\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydbsql = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"789456565632\",\n",
    "  database=\"TwitterDB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydbsql.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "1007 (HY000): Can't create database 'twitterdb'; database exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m             self._cmysql.query(query,\n\u001b[0m\u001b[0;32m    507\u001b[0m                                \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Can't create database 'twitterdb'; database exists",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7b6cbe716c2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#create DATABASE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmycursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CREATE DATABASE TwitterDB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\mysql\\connector\\cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             result = self._cnx.cmd_query(stmt, raw=self._raw,\n\u001b[0m\u001b[0;32m    270\u001b[0m                                          \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                                          raw_as_string=self._raw_as_string)\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    508\u001b[0m                                raw_as_string=raw_as_string)\n\u001b[0;32m    509\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m             raise errors.get_mysql_exception(exc.errno, msg=exc.msg,\n\u001b[0m\u001b[0;32m    511\u001b[0m                                              sqlstate=exc.sqlstate)\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: 1007 (HY000): Can't create database 'twitterdb'; database exists"
     ]
    }
   ],
   "source": [
    "#create DATABASE\n",
    "mycursor.execute(\"CREATE DATABASE TwitterDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Table\n",
    "#mycursor.execute(\"USE TwitterDB\")\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS user(\"+\n",
    "                 \"user_id VARCHAR(255) PRIMARY KEY,\"+\n",
    "                \"name VARCHAR(255),\"+\n",
    "                \"screen_name VARCHAR(255),\"+\n",
    "                \"location VARCHAR(255),\"+\n",
    "                \"description VARCHAR(255),\"+\n",
    "                \"followers_count INT NOT NULL,\"+\n",
    "                \"friends_count INT NOT NULL,\"+\n",
    "                \"listed_count INT NOT NULL,\"+\n",
    "                \"favourites_count INT NOT NULL,\"+\n",
    "                \"statuses_count INT NOT NULL,\"+\n",
    "                \"created_at DATETIME NOT NULL);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS post(\"+\n",
    "                 \"user_id VARCHAR(255) NOT NULL,\"+\n",
    "                 \"post_id VARCHAR(255) NOT NULL,\"+\n",
    "                 \"created_at DATETIME NOT NULL,\"+\n",
    "                 \"PRIMARY KEY (user_id, post_id),\"+\n",
    "                 \"FOREIGN KEY (user_id) REFERENCES user(user_id));\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop user table for test\n",
    "sql = \"DROP TABLE post\"\n",
    "mycursor.execute(sql)\n",
    "sql = \"DROP TABLE user\"\n",
    "mycursor.execute(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database\n",
    "mydbmongo = myclient[\"TwitterDB\"]\n",
    "#create collection\n",
    "mycol = mydbmongo[\"Tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-58ba63afac64>:91: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  if mycol.find({'_id': tweet_id}).limit(1).count() > 0:\n"
     ]
    }
   ],
   "source": [
    "#start loading\n",
    "#load function first\n",
    "\n",
    "with open(\"AI-out\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        \n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            #print(data['id'])\n",
    "            ProcessData(data) \n",
    "            \n",
    "        except OSError as err:\n",
    "            print(\"OS error: {0}\".format(err))\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessData(data):\n",
    "    \n",
    "#-----------user infomation----------\n",
    "    #tweet user\n",
    "    if checkExist(data['user'][\"id\"]):\n",
    "        #already exist \n",
    "        updateUser(data['user'])\n",
    "    else:\n",
    "        #new user\n",
    "        createNewUser(data['user']) \n",
    "        \n",
    "        \n",
    "    #retweet user\n",
    "    if \"retweeted_status\" in data:\n",
    "        if checkExist(data['retweeted_status']['user'][\"id\"]):\n",
    "            #already exist\n",
    "            updateUser(data['retweeted_status']['user'])\n",
    "        else:\n",
    "            #new user\n",
    "            createNewUser(data['retweeted_status']['user'])\n",
    "            \n",
    "#------------post ----------------\n",
    "    newPost(data)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkExist(user_id):\n",
    "    idquery= \"SELECT COUNT(1) FROM user WHERE user_id = \"+str(user_id)+\";\"\n",
    "    mycursor.execute(idquery)\n",
    "    myresult = mycursor.fetchall()\n",
    "\n",
    "    if(myresult[0][0]!=0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewUser(data):\n",
    "    user_id = data[\"id\"]\n",
    "    name = data[\"name\"]\n",
    "    screen_name=data[\"screen_name\"]\n",
    "    location = data[\"location\"]\n",
    "    description = data[\"description\"]\n",
    "    followers_count = data[\"followers_count\"]\n",
    "    friends_count = data[\"friends_count\"]\n",
    "    listed_count = data[\"listed_count\"]\n",
    "    favourites_count = data[\"favourites_count\"]\n",
    "    statuses_count = data[\"statuses_count\"]\n",
    "    \n",
    "    new_datetime = datetime.strftime(datetime.strptime(data[\"created_at\"],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "    created_at = new_datetime\n",
    "    \n",
    "    sql = (\"INSERT INTO user (user_id, name, screen_name, location,\"+\n",
    "    \" description, followers_count, friends_count, listed_count, favourites_count, statuses_count, created_at)\"+\n",
    "    \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "    val=(user_id,name,screen_name,location,description,int(followers_count)\n",
    "         ,int(friends_count),int(listed_count),int(favourites_count),int(statuses_count),created_at)\n",
    " \n",
    "    mycursor.execute(sql, val)\n",
    "    mydbsql.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateUser(data):\n",
    "    user_id = data[\"id\"]\n",
    "    name = data[\"name\"]\n",
    "    screen_name=data[\"screen_name\"]\n",
    "    location = data[\"location\"]\n",
    "    description = data[\"description\"]\n",
    "    followers_count = data[\"followers_count\"]\n",
    "    friends_count = data[\"friends_count\"]\n",
    "    listed_count = data[\"listed_count\"]\n",
    "    favourites_count = data[\"favourites_count\"]\n",
    "    statuses_count = data[\"statuses_count\"]\n",
    "    \n",
    "    sql = (\"UPDATE user SET name = %s, \"+\n",
    "    \"screen_name= %s, \"+\n",
    "    \"location= %s, \"+\n",
    "    \"description= %s, \"+\n",
    "    \"followers_count= %s, \"+\n",
    "    \"friends_count= %s, \"+\n",
    "    \"listed_count= %s, \"+\n",
    "    \"favourites_count= %s, \"+\n",
    "    \"statuses_count= %s \"+\n",
    "    \"WHERE user_id = %s\")\n",
    "    \n",
    "    \n",
    "    val = (name,screen_name,location,description,int(followers_count),\n",
    "           int(friends_count),int(listed_count),int(favourites_count),int(statuses_count),user_id)\n",
    "    #print(sql)\n",
    "    mycursor.execute(sql, val)\n",
    "    mydbsql.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newPost(data):\n",
    "    if \"retweeted_status\" in data:\n",
    "        # it is a RT\n",
    "        RT = 1\n",
    "        \n",
    "        #for tweet\n",
    "        if \"extended_tweet\" in data:\n",
    "            #for tweet mongoDB\n",
    "            tweet_id = data['id']\n",
    "            text_full = data['extended_tweet']['full_text']\n",
    "            text=text_full.partition('RT')[0]\n",
    "            \n",
    "            hashtag = []\n",
    "            if(\"extended_tweet\" in data['retweeted_status']):\n",
    "                for ht in (data['retweeted_status']['extended_tweet']['entities']['hashtags']):\n",
    "                    hashtag.append(ht['text'])\n",
    "            else:\n",
    "                for ht in (data['retweeted_status']['entities']['hashtags']):\n",
    "                    hashtag.append(ht['text'])\n",
    "        \n",
    "            new_datetime = datetime.strftime(datetime.strptime(data[\"created_at\"],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "            created_at = new_datetime\n",
    "        \n",
    "            quote_count=data['quote_count']\n",
    "            reply_count=data['reply_count']\n",
    "            retweet_count=data['retweet_count']\n",
    "            favorite_count=data['favorite_count']\n",
    "            \n",
    "            user_id=data['user']['id']\n",
    "            user_screen_name=data['user']['screen_name']\n",
    "            \n",
    "            rt_id=data['retweeted_status']['id']\n",
    "            \n",
    "        \n",
    "            mydict = { \"_id\": tweet_id,\"RT\":RT,\"text\":text,\"hashtag\":hashtag,\"created_at\":created_at,\n",
    "                      \"quote_count\":quote_count,\"reply_count\":reply_count,\"retweet_count\":retweet_count,\n",
    "                      \"favorite_count\":favorite_count,\"user_screen_name\":user_screen_name,\"rt_id\":rt_id}\n",
    "        \n",
    "            x = mycol.insert_one(mydict)\n",
    "        \n",
    "            #for post table mySQL\n",
    "        \n",
    "            sql = (\"INSERT INTO post (user_id, post_id, created_at) VALUES (%s, %s, %s)\")\n",
    "            val=(user_id,tweet_id,created_at)\n",
    "        \n",
    "            mycursor.execute(sql, val)\n",
    "            mydbsql.commit()\n",
    "        \n",
    "        else:\n",
    "            #for tweet mongoDB\n",
    "            tweet_id = data['id']\n",
    "            text_full = data['text']\n",
    "            text=text_full.partition('RT')[0]\n",
    "            \n",
    "            hashtag = []\n",
    "            if(\"extended_tweet\" in data['retweeted_status']):\n",
    "                for ht in (data['retweeted_status']['extended_tweet']['entities']['hashtags']):\n",
    "                    hashtag.append(ht['text'])\n",
    "            else:\n",
    "                for ht in (data['retweeted_status']['entities']['hashtags']):\n",
    "                    hashtag.append(ht['text'])\n",
    "        \n",
    "            new_datetime = datetime.strftime(datetime.strptime(data[\"created_at\"],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "            created_at = new_datetime\n",
    "        \n",
    "            quote_count=data['quote_count']\n",
    "            reply_count=data['reply_count']\n",
    "            retweet_count=data['retweet_count']\n",
    "            favorite_count=data['favorite_count']\n",
    "            \n",
    "            user_screen_name=data['user']['screen_name']\n",
    "            rt_id=data['retweeted_status']['id']\n",
    "        \n",
    "            mydict = { \"_id\": tweet_id,\"RT\":RT,\"text\":text,\"hashtag\":hashtag,\"created_at\":created_at,\n",
    "                      \"quote_count\":quote_count,\"reply_count\":reply_count,\"retweet_count\":retweet_count,\n",
    "                      \"favorite_count\":favorite_count,\"user_screen_name\":user_screen_name,\"rt_id\":rt_id}\n",
    "        \n",
    "            x = mycol.insert_one(mydict)\n",
    "        \n",
    "            #for post table mySQL\n",
    "            user_id=data['user']['id']\n",
    "        \n",
    "            sql = (\"INSERT INTO post (user_id, post_id, created_at) VALUES (%s, %s, %s)\")\n",
    "            val=(user_id,tweet_id,created_at)\n",
    "        \n",
    "            mycursor.execute(sql, val)\n",
    "            mydbsql.commit()\n",
    "        \n",
    "        #for retweet\n",
    "        tweet_id = data['retweeted_status']['id']\n",
    "        if mycol.find({'_id': tweet_id}).limit(1).count() > 0:\n",
    "            # existed retweet\n",
    "            pass\n",
    "        else:\n",
    "            # new retweet\n",
    "            #print(data['retweeted_status'])\n",
    "            insertNewPost(data['retweeted_status'])\n",
    "        \n",
    "    else:\n",
    "        # not a RT\n",
    "        insertNewPost(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertNewPost(data):\n",
    "    if \"extended_tweet\" in data:\n",
    "        #for tweet mongoDB\n",
    "        tweet_id = data['id']\n",
    "        RT = 0\n",
    "        text = data['extended_tweet']['full_text']\n",
    "        hashtag = []\n",
    "        for ht in (data['extended_tweet']['entities']['hashtags']):\n",
    "            hashtag.append(ht['text'])\n",
    "        \n",
    "        new_datetime = datetime.strftime(datetime.strptime(data[\"created_at\"],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "        created_at = new_datetime\n",
    "    \n",
    "        quote_count=data['quote_count']\n",
    "        reply_count=data['reply_count']\n",
    "        retweet_count=data['retweet_count']\n",
    "        favorite_count=data['favorite_count']\n",
    "            \n",
    "        user_id=data['user']['id']\n",
    "        user_screen_name=data['user']['screen_name']\n",
    "        \n",
    "        mydict = { \"_id\": tweet_id,\"RT\":RT,\"text\":text,\"hashtag\":hashtag,\"created_at\":created_at,\n",
    "                  \"quote_count\":quote_count,\"reply_count\":reply_count,\"retweet_count\":retweet_count,\n",
    "                  \"favorite_count\":favorite_count,\"user_screen_name\":user_screen_name}\n",
    "        \n",
    "        x = mycol.insert_one(mydict)\n",
    "        \n",
    "        #for post table mySQL\n",
    "        \n",
    "        sql = (\"INSERT INTO post (user_id, post_id, created_at) VALUES (%s, %s, %s)\")\n",
    "        val=(user_id,tweet_id,created_at)\n",
    "    \n",
    "        mycursor.execute(sql, val)\n",
    "        mydbsql.commit()\n",
    "        \n",
    "    else:\n",
    "        #for tweet mongoDB\n",
    "        tweet_id = data['id']\n",
    "        RT = 0\n",
    "        text = data['text']\n",
    "        hashtag = []\n",
    "        for ht in (data['entities']['hashtags']):\n",
    "            hashtag.append(ht['text'])\n",
    "        \n",
    "        new_datetime = datetime.strftime(datetime.strptime(data[\"created_at\"],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "        created_at = new_datetime\n",
    "        \n",
    "        quote_count=data['quote_count']\n",
    "        reply_count=data['reply_count']\n",
    "        retweet_count=data['retweet_count']\n",
    "        favorite_count=data['favorite_count']\n",
    "            \n",
    "        user_screen_name=data['user']['screen_name']\n",
    "        \n",
    "        mydict = { \"_id\": tweet_id,\"RT\":RT,\"text\":text,\"hashtag\":hashtag,\"created_at\":created_at,\n",
    "                  \"quote_count\":quote_count,\"reply_count\":reply_count,\"retweet_count\":retweet_count,\n",
    "                  \"favorite_count\":favorite_count,\"user_screen_name\":user_screen_name}\n",
    "        \n",
    "        x = mycol.insert_one(mydict)\n",
    "        \n",
    "        #for post table mySQL\n",
    "        user_id=data['user']['id']\n",
    "        \n",
    "        sql = (\"INSERT INTO post (user_id, post_id, created_at) VALUES (%s, %s, %s)\")\n",
    "        val=(user_id,tweet_id,created_at)\n",
    "        \n",
    "        mycursor.execute(sql, val)\n",
    "        mydbsql.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 1380932241287692288, 'RT': 0, 'text': 'The latest Jimi Hendrix Daily News! https://t.co/ebDcoqixoc Thanks to @YvonneMcCulley1 @BMFDV #artificialintelligence', 'hashtag': ['artificialintelligence'], 'created_at': '2021-04-10 17:14:37', 'quote_count': 0, 'reply_count': 0, 'retweet_count': 0, 'favorite_count': 0, 'user_screen_name': 'experienceads'}]\n"
     ]
    }
   ],
   "source": [
    "total=[]\n",
    "for i in range(100):\n",
    "    t0 = time.time()\n",
    "    res=[]\n",
    "\n",
    "    myquery = { \"user_screen_name\": \"experienceads\" }\n",
    "    mydoc = mycol.find(myquery)\n",
    "\n",
    "    for y in mydoc:\n",
    "        res.append(y) \n",
    "        \n",
    "    t1 = time.time()\n",
    "    total.append(t1-t0) \n",
    "\n",
    "np.average(total)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006366369724273682"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=[]\n",
    "for i in range(100):\n",
    "    res=[]\n",
    "    t0 = time.time()\n",
    "    sql = \"SELECT * FROM post WHERE user_id= 10541332;\"\n",
    "\n",
    "    mycursor.execute(sql)\n",
    "    myresult = mycursor.fetchall()\n",
    "\n",
    "    for x in myresult:\n",
    "        myquery = { \"_id\": int(x[1]) }\n",
    "        mydoc = mycol.find(myquery)\n",
    "        \n",
    "        for y in mydoc:\n",
    "            res.append(y)\n",
    "            \n",
    "        \n",
    "    t1 = time.time()\n",
    "    total.append(t1-t0) \n",
    "\n",
    "np.average(total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchUser(name):\n",
    "    \n",
    "    sql = \"SELECT * FROM user WHERE (user_id = %s) OR (name = %s) OR (screen_name = %s);\"\n",
    "    val=(name,name,name)\n",
    "    \n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    myresult = mycursor.fetchall()\n",
    "\n",
    "    \n",
    "    x=myresult[0]\n",
    "    df = pd.DataFrame([list(x),], columns =[\"id\", \"name\", \"screen_name\", \"location\",\n",
    "                                            \"description\",\"followers_count\",\"friends_count\",\n",
    "                                            \"listed_count\",\"favourites_count\",\"statuses_count\",\"created_at\"])\n",
    "    print(df)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    user_id=x[0]\n",
    "    sql = \n",
    "    \n",
    "    \n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 1207040017350242304,\n",
       "  'RT': 0,\n",
       "  'text': 'Artificial intelligence and automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required? @CIOdive @its_ahickey #artificialintelligence #highereducation #college \\nhttps://t.co/r2SRhz6Ymp',\n",
       "  'hashtag': ['AI', 'artificialintelligence', 'highereducation', 'college'],\n",
       "  'created_at': '2019-12-17 20:49:00',\n",
       "  'quote_count': 1,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 180,\n",
       "  'favorite_count': 34,\n",
       "  'user_screen_name': 'axelrod_eric'},\n",
       " {'_id': 1207030957938814976,\n",
       "  'RT': 0,\n",
       "  'text': '#artificialintelligence and #automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required? @CIOdive @its_ahickey #highereducation #college #university\\nhttps://t.co/JQnLaOhnWC',\n",
       "  'hashtag': ['artificialintelligence',\n",
       "   'automation',\n",
       "   'AI',\n",
       "   'highereducation',\n",
       "   'college',\n",
       "   'university'],\n",
       "  'created_at': '2019-12-17 20:13:00',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 109,\n",
       "  'favorite_count': 30,\n",
       "  'user_screen_name': 'clouddatasummit'},\n",
       " {'_id': 1344395301935849473,\n",
       "  'RT': 0,\n",
       "  'text': '#artificialintelligence and #automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required? @CIOdive @its_ahickey #highereducation #college #university #ai\\nhttps://t.co/y3OppT9jle',\n",
       "  'hashtag': ['artificialintelligence',\n",
       "   'automation',\n",
       "   'AI',\n",
       "   'highereducation',\n",
       "   'college',\n",
       "   'university',\n",
       "   'ai'],\n",
       "  'created_at': '2020-12-30 21:29:52',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 100,\n",
       "  'favorite_count': 14,\n",
       "  'user_screen_name': 'digr_io'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def searchTag(hashtag):\n",
    "    res = []\n",
    "    \n",
    "    myquery = {\"hashtag\": hashtag}\n",
    "    mydoc = mycol.find(myquery).sort(\"retweet_count\", -1)\n",
    "    \n",
    "    for y in mydoc:\n",
    "        res.append(y)\n",
    "    \n",
    "    if res:\n",
    "        return res\n",
    "    else:\n",
    "        print(\"No tweets relates to this hashtag\")\n",
    "    \n",
    "searchTag(\"artificialintelligence\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(date_text):\n",
    "    try:\n",
    "        datetime.strptime(date_text, \"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\")\n",
    "        \n",
    "def searchtime(beginning, ending):\n",
    "    res = []\n",
    "    \n",
    "    #validate if user input correct format of date\n",
    "    validate(beginning)\n",
    "    validate(ending)\n",
    "    \n",
    "    beginning = beginning + str(\" 00:00:00\")\n",
    "    ending = ending + str(\" 23:59:59\")\n",
    "    myquery = {\"created_at\": {\n",
    "        \"$gte\": beginning,\n",
    "        \"$lte\": ending\n",
    "    } \n",
    "    }\n",
    "    mydoc = mycol.find(myquery).sort(\"created_at\", -1)\n",
    "    \n",
    "    for i in mydoc:\n",
    "        res.append(i)\n",
    "    \n",
    "    return res\n",
    "\n",
    "#new_datetime = datetime.strftime(datetime.strptime(data[\"created_at\"],'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "#created_at = new_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 1344395301935849473,\n",
       "  'RT': 0,\n",
       "  'text': '#artificialintelligence and #automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required? @CIOdive @its_ahickey #highereducation #college #university #ai\\nhttps://t.co/y3OppT9jle',\n",
       "  'hashtag': ['artificialintelligence',\n",
       "   'automation',\n",
       "   'AI',\n",
       "   'highereducation',\n",
       "   'college',\n",
       "   'university',\n",
       "   'ai'],\n",
       "  'created_at': '2020-12-30 21:29:52',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 100,\n",
       "  'favorite_count': 14,\n",
       "  'user_screen_name': 'digr_io'},\n",
       " {'_id': 1343519651985240064,\n",
       "  'RT': 0,\n",
       "  'text': \"5⭐️...elements of thrilling mystery, suspense, dystopian fantasy and science fiction.'\\n\\nThe Lenders Saga from @Travis_Borne.\\n\\n#scifi #sciencefiction #AI #ArtificialIntelligence #Aliens #timetravel #apocalypse #IARTG #ASMSG \\n#Kindle #books #ebooks \\nhttps://t.co/kqLbqCb1g9 https://t.co/pfeoSDXTqI\",\n",
       "  'hashtag': ['scifi',\n",
       "   'sciencefiction',\n",
       "   'AI',\n",
       "   'ArtificialIntelligence',\n",
       "   'Aliens',\n",
       "   'timetravel',\n",
       "   'apocalypse',\n",
       "   'IARTG',\n",
       "   'ASMSG',\n",
       "   'Kindle',\n",
       "   'books',\n",
       "   'ebooks'],\n",
       "  'created_at': '2020-12-28 11:30:21',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 31,\n",
       "  'favorite_count': 12,\n",
       "  'user_screen_name': 'TwitrPartner'},\n",
       " {'_id': 1341435841978265601,\n",
       "  'RT': 0,\n",
       "  'text': \"5⭐️...elements of thrilling mystery, suspense, dystopian fantasy and science fiction.'\\n\\nThe Lenders Saga from @Travis_Borne.\\n\\n#scifi #sciencefiction #AI #ArtificialIntelligence #Aliens #timetravel #apocalypse #IARTG #ASMSG \\n#Kindle #books #ebooks \\nhttps://t.co/ADmMk5zoE4 https://t.co/iJATBGOo5V\",\n",
       "  'hashtag': ['scifi',\n",
       "   'sciencefiction',\n",
       "   'AI',\n",
       "   'ArtificialIntelligence',\n",
       "   'Aliens',\n",
       "   'timetravel',\n",
       "   'apocalypse',\n",
       "   'IARTG',\n",
       "   'ASMSG',\n",
       "   'Kindle',\n",
       "   'books',\n",
       "   'ebooks'],\n",
       "  'created_at': '2020-12-22 17:30:02',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 58,\n",
       "  'favorite_count': 18,\n",
       "  'user_screen_name': 'Raymond_Norman'},\n",
       " {'_id': 1340273230725193730,\n",
       "  'RT': 0,\n",
       "  'text': \"5⭐️...elements of thrilling mystery, suspense, dystopian fantasy and science fiction.'\\n\\nThe Lenders Saga from @Travis_Borne.\\n\\n#scifi #sciencefiction #AI #ArtificialIntelligence #Aliens #timetravel #apocalypse #IARTG #ASMSG \\n#Kindle #books #ebooks \\nhttps://t.co/LZ01I3xqJO https://t.co/d5FMF7H8NK\",\n",
       "  'hashtag': ['scifi',\n",
       "   'sciencefiction',\n",
       "   'AI',\n",
       "   'ArtificialIntelligence',\n",
       "   'Aliens',\n",
       "   'timetravel',\n",
       "   'apocalypse',\n",
       "   'IARTG',\n",
       "   'ASMSG',\n",
       "   'Kindle',\n",
       "   'books',\n",
       "   'ebooks'],\n",
       "  'created_at': '2020-12-19 12:30:13',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 64,\n",
       "  'favorite_count': 22,\n",
       "  'user_screen_name': 'MainChannel_'},\n",
       " {'_id': 1339925923307552769,\n",
       "  'RT': 0,\n",
       "  'text': \"5⭐️...elements of thrilling mystery, suspense, dystopian fantasy and science fiction.'\\n\\nThe Lenders Saga from @Travis_Borne.\\n\\n#scifi #sciencefiction #AI #ArtificialIntelligence #Aliens #timetravel #apocalypse #IARTG #ASMSG \\n#Kindle #books #ebooks \\nhttps://t.co/kqLbqCsC7H https://t.co/RRtOIq1x50\",\n",
       "  'hashtag': ['scifi',\n",
       "   'sciencefiction',\n",
       "   'AI',\n",
       "   'ArtificialIntelligence',\n",
       "   'Aliens',\n",
       "   'timetravel',\n",
       "   'apocalypse',\n",
       "   'IARTG',\n",
       "   'ASMSG',\n",
       "   'Kindle',\n",
       "   'books',\n",
       "   'ebooks'],\n",
       "  'created_at': '2020-12-18 13:30:09',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 43,\n",
       "  'favorite_count': 12,\n",
       "  'user_screen_name': 'TwitrPartner'},\n",
       " {'_id': 1305570901027696646,\n",
       "  'RT': 0,\n",
       "  'text': \"#100DaysOfCode #100DaysOfCloud #100DaysOfMLCode #java #coder #CodeNewbie  #developer #javascript #ArtificialIntelligence #python #java #internet #InternetOfThings  #Serverless #programming #coding #Cloud #code #udemy \\n\\nI've build a #Twitter #Bot in Java - check the sample video https://t.co/qVxh9TPdfd\",\n",
       "  'hashtag': ['100DaysOfCode',\n",
       "   '100DaysOfCloud',\n",
       "   '100DaysOfMLCode',\n",
       "   'java',\n",
       "   'coder',\n",
       "   'CodeNewbie',\n",
       "   'developer',\n",
       "   'javascript',\n",
       "   'ArtificialIntelligence',\n",
       "   'python',\n",
       "   'java',\n",
       "   'internet',\n",
       "   'InternetOfThings',\n",
       "   'Serverless',\n",
       "   'programming',\n",
       "   'coding',\n",
       "   'Cloud',\n",
       "   'code',\n",
       "   'udemy',\n",
       "   'Twitter',\n",
       "   'Bot'],\n",
       "  'created_at': '2020-09-14 18:15:33',\n",
       "  'quote_count': 1,\n",
       "  'reply_count': 5,\n",
       "  'retweet_count': 153,\n",
       "  'favorite_count': 58,\n",
       "  'user_screen_name': 'AlexRosu1989'},\n",
       " {'_id': 1229961247979753472,\n",
       "  'RT': 0,\n",
       "  'text': 'This website has everything I learned about #AI in my career. 👨\\u200d🎓 Now I can go back to grandfather duty 👨\\u200d👧\\u200d👧!\\n\\nhttps://t.co/pS3o4Xeugc\\n\\nPlease comment. #ArtificialIntelligence #MachineLearning',\n",
       "  'hashtag': ['AI', 'ArtificialIntelligence', 'MachineLearning'],\n",
       "  'created_at': '2020-02-19 02:49:47',\n",
       "  'quote_count': 20,\n",
       "  'reply_count': 41,\n",
       "  'retweet_count': 681,\n",
       "  'favorite_count': 619,\n",
       "  'user_screen_name': 'AdrianZidaritz'},\n",
       " {'_id': 1207040017350242304,\n",
       "  'RT': 0,\n",
       "  'text': 'Artificial intelligence and automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required? @CIOdive @its_ahickey #artificialintelligence #highereducation #college \\nhttps://t.co/r2SRhz6Ymp',\n",
       "  'hashtag': ['AI', 'artificialintelligence', 'highereducation', 'college'],\n",
       "  'created_at': '2019-12-17 20:49:00',\n",
       "  'quote_count': 1,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 180,\n",
       "  'favorite_count': 34,\n",
       "  'user_screen_name': 'axelrod_eric'},\n",
       " {'_id': 1207030957938814976,\n",
       "  'RT': 0,\n",
       "  'text': '#artificialintelligence and #automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required? @CIOdive @its_ahickey #highereducation #college #university\\nhttps://t.co/JQnLaOhnWC',\n",
       "  'hashtag': ['artificialintelligence',\n",
       "   'automation',\n",
       "   'AI',\n",
       "   'highereducation',\n",
       "   'college',\n",
       "   'university'],\n",
       "  'created_at': '2019-12-17 20:13:00',\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 109,\n",
       "  'favorite_count': 30,\n",
       "  'user_screen_name': 'clouddatasummit'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchtime(\"2019-12-16\", \"2021-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    while True:\n",
    "        statement = input(\"For user search, enter 1\\n\"+\"For tweet search, enter 2\\n\"+\n",
    "                          \"For hashtag search, enter 3\\n\"+\"For time range search, enter 4\\n\"+\n",
    "                          \"To exit, enter 0\\n\")\n",
    "        if(statement=='0'):\n",
    "            print(\"Exit\")\n",
    "            break\n",
    "        elif(statement=='1'):\n",
    "            statement = input(\"Please enter the user name, screen name, or id:\\n\")\n",
    "            searchUser(statement)\n",
    "            break\n",
    "        elif(statement=='2'):\n",
    "            break\n",
    "        elif(statement=='3'):\n",
    "            break\n",
    "        elif(statement=='4'):\n",
    "            break\n",
    "        else:\n",
    "            print(\"invalid input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user search, enter 1\n",
      "For tweet search, enter 2\n",
      "For hashtag search, enter 3\n",
      "For time range search, enter 4\n",
      "To exit, enter 0\n",
      "1\n",
      "Please enter the user name, screen name, or id:\n",
      "experienceads\n",
      "         id     name    screen_name     location  \\\n",
      "0  10541332  Evan W.  experienceads  Sunrise, FL   \n",
      "\n",
      "                                         description  followers_count  \\\n",
      "0  #InternetMarketing enthusiast at Experience Ad...            11895   \n",
      "\n",
      "   friends_count  listed_count  favourites_count  statuses_count  \\\n",
      "0          13197           637              7185           30353   \n",
      "\n",
      "           created_at  \n",
      "0 2007-11-25 02:13:29  \n"
     ]
    }
   ],
   "source": [
    "search()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, key, value, next, prev):\n",
    "        self.value = value\n",
    "        self.key = key\n",
    "        self.after = after\n",
    "        self.prev = prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublyLinkedList(object):\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        self.__size = 0\n",
    "        \n",
    "    # insert at beginning of linkedlist\n",
    "    def append(self, node):\n",
    "        if self.head == None:\n",
    "            new_Node = Node(node)\n",
    "            self.head = new_Node\n",
    "        else:\n",
    "            new_Node = Node(node)\n",
    "            self.head.prev = new_Node\n",
    "            new_Node.next = self.head\n",
    "            self.head = new_Node\n",
    "\n",
    "    #remove and return the node we want \n",
    "    def remove(self, node):\n",
    "        if self.head == node:\n",
    "            self.head = self.head.next\n",
    "        if self.tail == node:\n",
    "            self.tail = self.tail.prev\n",
    "\n",
    "        next_node = node.next\n",
    "        prev_node = node.prev\n",
    "\n",
    "        if prev_node:\n",
    "            prev_node.next = next_node\n",
    "        if next_node:\n",
    "            next_node.prev = prev_node\n",
    "\n",
    "        self.__size -= 1\n",
    "        return node\n",
    "    \n",
    "    #remove and return last node\n",
    "    def pop(self):\n",
    "        tail_node = self.tail\n",
    "        prev_node = tail_node.prev\n",
    "        \n",
    "        if prev_node:\n",
    "            prev_node.next = None\n",
    "            \n",
    "        self.tail = prev_node\n",
    "        \n",
    "        self.__size -= 1\n",
    "        \n",
    "        return tail_node\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.__size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self._capacity = capacity\n",
    "        self._lookup = {}\n",
    "        self._data = DoublyLinkedList()\n",
    "\n",
    "    def set(self, key, value):\n",
    "        if key in self._lookup: \n",
    "            current_node = self._lookup[key]\n",
    "            current_node.value = value\n",
    "\n",
    "            self._data.remove(current_node)\n",
    "            self._data.append(current_node)\n",
    "        else:\n",
    "            new_node = Node(key, value)\n",
    "            self._lookup[key] = new_node\n",
    "            self._data.append(new_node)\n",
    "        \n",
    "        # if larger than capacity \n",
    "        if len(self._lookup) > self._capacity:\n",
    "            stale_node = self._data.pop()\n",
    "            del self._lookup[stale_node.key]\n",
    "\n",
    "\n",
    "        def get(self, key):\n",
    "            if key not in self._lookup: \n",
    "                return \n",
    "            current_node = self._lookup[key]\n",
    "            self._data.remove(current_node)\n",
    "            self._data.append(current_node)\n",
    "            return current_node.value\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self._data.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
